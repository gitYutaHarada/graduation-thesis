\chapter{使用データと前処理}

本章では，本研究で使用したデータセットの概要と，機械学習モデルの学習に適した形式に変換するための前処理手法について述べる．特に，交通事故予測において致命的な問題となる「データリーク」の排除と，モデルの汎用性を高めるための特徴量エンジニアリングの過程について詳述する．

\section{データセットの概要}

　本研究では，分析の基礎データとして，警察庁が公開している「交通事故統計オープンデータ」~\cite{traffic_stats_estat}を採用した．このデータセットは，日本政府が推進する「世界最先端デジタル国家創造宣言・官民データ活用推進基本計画」に基づき，交通事故抑止や交通安全対策の高度化を目的として一般公開されているものである．
分析対象期間は，2019年から2024年までの6年間とした．本データセットは，日本国内で発生したすべての「人身事故（死亡または負傷を伴う事故）」を網羅しており，各事故について警察官が現場検分等を通じて記録した詳細な情報が含まれている．

データの形式は，都道府県別や月別にあらかじめ集計された統計表ではなく，発生した事故の1件1件が独立したデータ（レコード）として詳細に記録された形式で提供されている点が特徴である．

\begin{itemize}
    \item \textbf{事故管理情報}：発生日時，発生場所（緯度・経度，都道府県，市区町村），天候，路面状態など
    \item \textbf{道路・環境情報}：道路形状，信号機の有無，道路幅員，規制速度，一時停止規制など
    \item \textbf{当事者情報}：当事者の年齢，性別，車両の形状，衝突部位，損傷程度など
\end{itemize}

オープンデータは年ごとに個別のCSVファイルとして提供されており，各項目は「コードブック（データ定義書）」に基づいた数値コード（例：晴れ=1，曇り=2）で管理されている．本研究では，Pythonのデータ解析ライブラリであるPandasを用いてこれら6年分のデータを結合し，一つの統合データフレームを作成した．
統合後の総レコード数は約189万件（1,895,275件）に上る．このサンプルサイズは，単年度の分析では統計的な有意差を見出すことが困難な「死亡事故」のような稀な事象の特性を学習するために十分な規模であり，かつ長期的なトレンドや季節性をモデルに取り込むことを可能にするものである．

\section{データクリーニングとリークの排除}
　本研究におけるデータクリーニングの工程では，まずデータの欠損や形式の整合性を確認した．\textbf{事前調査の結果，本データセットにおいて欠損値が含まれるレコードは全体の0\%であり，データの完全性が極めて高いことが確認された．したがって，欠損値に対する特別な処理（削除や補完）は不要であると判断し，全レコードを分析に使用した．}

次に，予測モデルの構築にあたり最も注意を要する「データリーク（Data Leakage）」の排除を重点的に実施した．
データリークとは，予測を行う時点では入手不可能な情報が学習データに含まれてしまう現象を指し，これが見過ごされると，モデルは実運用で機能しない虚偽の高精度を出力してしまう．
本データセットに含まれる変数のうち，「事故内容」「人身損傷程度」「車両の損壊程度」などの項目は，事故が発生し，警察による検分が行われた後に確定する「事後情報」である．例えば，「事故内容」カラムには「死亡」や「負傷」といった結果が直接記述されており，これを入力変数として用いることは，答えを見ながら問題を解くことに等しい．
したがって本研究では，これらの事後情報を含む計14カラムをデータリークの原因となる変数と見なし，学習用データから完全に除外した．これにより，事故発生直前の状況や環境要因のみからリスクを予測するという，実用的な問題設定を厳密に守っている．

\section{特徴量エンジニアリング}
　元のデータセットに含まれる変数は，必ずしも機械学習モデルが解釈しやすい形式ではない．そこで，モデルの学習効率と予測精度を向上させるため，以下の3つの観点から特徴量エンジニアリングを実施した．

\subsection{日時データの分解}
　元データの「発生日時」は日付と時刻を含むタイムスタンプ形式であるが，多くの機械学習アルゴリズムはこれを直接扱うことができない．また，交通事故には「季節による路面状況の変化」や「時間帯による視界の変化」など，周期的な傾向が存在する．
そこで，「発生日時」カラムを「年（year）」「月（month）」「日（day）」「時間（hour）」の4つの数値データに分解した．これにより，モデルは年ごとのトレンド変化や，季節性・時間帯ごとのリスク変動を個別の特徴量として学習することが可能となる．なお，情報が重複するため，元の「発生日時」カラムは削除した．

\subsection{地理情報のクラスタリング (Geo-Clustering)}
　事故発生地点を示す「緯度」「経度」は，極めて詳細な位置情報を提供する一方で，そのまま連続値としてモデルに入力すると過学習（Overfitting）を引き起こすリスクがある．特定の交差点の座標そのものを記憶してしまうと，未知の地点での予測能力が低下するためである．
この問題に対処するため，本研究では教師なし学習の一種であるMiniBatchKMeans法を用いて，日本全国の発生地点を50個のエリア（クラスタ）に分割する処理を行った．各事故データには，緯度・経度の代わりに \texttt{area\_id}（0〜49のカテゴリ変数）を付与した．これにより，詳細すぎる座標情報を「地域特性」という抽象的な概念に変換し，モデルの汎用性を高めている．

\subsection{道路種別の集約}
　元データの「路線コード」は，国道や県道，バイパス区間などを区別するために約6,800種類のユニーク値を持っている．このようにカテゴリ数が膨大であると，データの希薄性を招き，モデルの学習が不安定になる．また，バイパスの区間番号のような微細な違いは，死亡事故リスクの予測において本質的な意味を持たない場合が多い．
そこで，路線コードの上位桁に基づき，道路を「一般国道」「主要地方道」「高速自動車国道」「市町村道」など，意味のある15種類のカテゴリ（\texttt{road\_type}）に集約した．この次元削減により，情報の粒度を適正化し，道路環境によるリスクの違いをモデルが捉えやすくなるよう設計した．

\section{目的変数の設定と不均衡データ}
　本研究の目的は，ある事故が「死亡事故」に至るか否かを予測することである．前述の通り「事故内容」カラムはリーク変数として削除したが，目的変数（正解ラベル）を作成するために，「死者数」カラムを用いた．
具体的には，死者数が1名以上の事故を「死亡事故（$y=1$）」，0名の事故を「非死亡事故（$y=0$）」と定義した．
ここで特筆すべきは，クラス間の極端な不均衡である．全データ約189万件のうち，死亡事故は約1.6万件に過ぎず，その比率はおよそ 118:1 となっている．このような不均衡データ（Imbalanced Data）をそのまま学習させると，モデルはすべてのデータを「非死亡事故」と予測するだけで99\%以上の正解率を出せてしまうため，死亡事故の検知に失敗する．この問題に対する対策（Class WeightおよびSMOTEの適用）については，次章の実験設定にて詳述する．